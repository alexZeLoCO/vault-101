# 1.1 Métodos de minería de datos
<% tp.file.creation_date() %> (YYYY-MM-DD) @ 17:35
Rodríguez López, Alejandro // UO281827

Tags:
	#showable
	Hecho en #EPI
	Sobre #Inteligencia_Negocio 
	Para #Apuntes
	Otros:
	Refs:
 
<hr>

- Regresión: Se busca por salida un número.
- Clasificación: Se busca por salida una categoría.
- Bayesian Learning: La salida es aquella categoría que sea más probable dados los datos de entrada.
- Basado en instancias: KNN. La salida es aquella de los K vecinos más cercanos.
- SVM: Buscar hiperplano que maximice el margen entre los puntos de distintas categorías más cercanos.

Extraer parte de la entrada puede ayudar a detectar cuál es la razón de la respuesta de un modelo. Si al omitir cierta información, el resultado cambia, implica que esa información es crucial para el resultado obtenido inicialmente.

<hr>

2023-09-15 (YYYY-MM-DD) @ 16:22

## Preparación de los datos

- Ajuste de datos de múltiples fuentes.
- Limpieza de datos (inconsistencias).
- Normalización de datos.
- Imputación de datos (datos perdidos).

### Búsqueda de atributos redundantes

Test de correlación chi-cuadrado. $e_{ij}$ es la frecuencia esperada del evento $(A_i, B_j)$.

$$
	\begin{matrix}
		x^2 = \sum_{i=1}^{c} \sum_{j=1}^{r} {{(o_{ij} - d_{ij})^2} \over {e_{ij}}} \\
		e_{ij} = {{count(A = a_i) \cdot count(B = b_j)} \over m}
	\end{matrix}
$$

<hr>

2023-09-18 (YYYY-MM-DD) @ 15:07

## Test chi-2

| - | - | - |
| --- | --- | --- |
|  |  | XX |
| XX | XXXX |  |
| XX |  |  |

| - | - | - |
| --- | --- | --- |
|  |  | $2 \over 10$ |
| $2 \over 10$ | $4 \over 10$ |  |
| $2 \over 10$ |  |  |

| P marginal. | - | - | - |
| --- | --- | --- | --- |
| $2 \over 10$ |  |  | $2 \over 10$ |
| $6 \over 10$ | $2 \over 10$ | $4 \over 10$ |  |
| $2 \over 10$ | $2 \over 10$ |  |  |
| | $4 \over 10$ | $4 \over 10$ | $2 \over 10$ |

| P marginal. | - | - | - |
| --- | --- | --- | --- |
| $2 \over 10$ |  |  | ${2 \cdot 2} \over { 10 \cdot 10}$ |
| $6 \over 10$ | ${2 \cdot 4} \over { 10 \cdot 10}$ | ${4 \cdot 6} \over {10 \cdot 10}$ |  |
| $2 \over 10$ | ${2 \cdot 4} \over {10 \cdot 10}$ |  |  |
| | $4 \over 10$ | $4 \over 10$ | $2 \over 10$ |

| P marginal. | - | - | - |
| --- | --- | --- | --- |
| $2 \over 10$ |  |  | ${2 \cdot 2} \over { 10 \cdot 10}$ |
| $6 \over 10$ | ${2 \cdot 4} \over { 10 \cdot 10}$ | ${4 \cdot 6} \over {10 \cdot 10}$ |  |
| $2 \over 10$ | ${2 \cdot 4} \over {10 \cdot 10}$ |  |  |
| | $4 \over 10$ | $4 \over 10$ | $2 \over 10$ |

| P marginal. | - | - | - |
| --- | --- | --- | --- |
| $2 \over 10$ |  |  | ${{2 \cdot 2} \over { 10 \cdot 10}} - {2 \over 10}$ |
| $6 \over 10$ | ${{2 \cdot 4} \over { 10 \cdot 10}} - {2 \over 10}$ | ${{4 \cdot 6} \over {10 \cdot 10}} - {4 \over 10}$ |  |
| $2 \over 10$ | ${{2 \cdot 4} \over {10 \cdot 10}} - {2 \over 10}$ |  |  |
| | $4 \over 10$ | $4 \over 10$ | $2 \over 10$ |

Si las casillas sale 0, las variables son independientes.
Cuanto más se alejen del 0, más dependientes son.

## Selección de características

Se pueden enfocar de 3 formas:

### Envolvente

Algoritmos genéticos.
Problemas de búsqueda en una cadena de bits.
Se utilizan clasificadores muy sensibles a variables que no están relacionadas con el problema.

### Filtro

### Selección por modelo o "embebida"
