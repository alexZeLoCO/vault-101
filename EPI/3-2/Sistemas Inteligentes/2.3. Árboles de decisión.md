2023-01-31 @ 14:41
Rodríguez López, Alejandro // UO281827

Tags: 
	Hecho en #EPI
	Sobre #Sistemas_Inteligentes 
	Para #Apuntes
	Otros: #Algoritmos
<hr>

Un árbol de decisión recibe un caso compuesto por varios atributos de entrada $(a, b, c)$.
![[2.3. Árboles de decisión 31-01-2023 14.43.00.excalidraw|1900]]
Se realizan preguntas respecto a los atributos de entrada. El problema consiste en averiguar cuál es la pregunta óptima que debería estar en la cima del árbol. Si una pregunta tiene posibilidad de predecir la solución directamente, es candidata a estar en la cima del árbol.
En el ejemplo anterior, la pregunta 'A?' es interesante porque si $A==a_3$, entonces la clase es 'Sí'.

La solución al problema consiste en hallar el atributo más independiente del set (aka Gini Impurity), o lo que es lo mismo, aquel que se mezcle menos. C4.5 contiene fórmulas utilizadas para medir la mezcla que hay entre varias clases.

---

Gini Impurity: Chance of being incorrect if you randomly assign a label to an example in the same set.
- Gini Impurity for the set `[A, A, A]` is 0 because there is only `A` in the dataset.
- Gini Impurity for the set `[A, B, C]` is ${ 1 \over 3 } = 0.\overline3$ because there are 3 distinct items in the dataset.
- Gini Impurity for the set `[A, A, B, B, C]` is