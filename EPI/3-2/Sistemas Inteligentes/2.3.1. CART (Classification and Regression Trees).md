2023-02-01 @ 14:58
Rodríguez López, Alejandro // UO281827

Tags:
	#showable
	Hecho en #Viesques
	Sobre #Sistemas_Inteligentes 
	Para #Extra
	Otros: #CART
	Refs:
		[[2.3. Árboles de decisión]]
		[[2.3.2. C4.5]]
		https://www.youtube.com/watch?v=LDRbO9a6XPU

<hr>

# CART

The following describes the usage of the CAST method.

## Gini impurity

Gini Impurity: Chance of being incorrect if you randomly assign a label to an example in the same set.
```python
def gini(rows):
	counts = class_counts(rows)
	impurity = 1
	for lbl in counts:
		prof_of_lbl = counts[lbl] / float(len(rows))
		impurity -= prob_of_lbl**2
	return impurity
```
- Gini Impurity for the set `[A, A, A]` is 0 because there is only `A` in the dataset.
- Gini Impurity for the set `[A, B, C]` is ${ 1 \over 3 } = 0.\overline3$ because there are 3 distinct items in the dataset.
- Gini Impurity for the set `[A, A, B, B, C]` is `gini([A, A, B, B, C])` => ${ 1 - { 2 \over 5 }^2 - { 2 \over 5 }^2 - { 1 \over 5 }^2 } = { 1 - { 2 \cdot { { 2 \over 5 }^2 } } - { 1 \over 5 }^2 } = { 1 - { 8 \over 25 } - { 1 \over 25 } } = { 1 - { 9 \over 25 } } = 0.64$.

## Example

Dataset:
| Color  | Diameter | Label |
| ------ | -------- | ----- |
| Green  | 3        | Apple |
| Yellow | 3        | Apple |
| Red    | 1        | Grape |
| Red    | 1        | Grape |
| Yellow | 3        | Lemon |

1. Calculate the impurity of the dataset:
	`gini([A, A, B, B, C])` => ${ 1 - { 2 \over 5 }^2 - { 2 \over 5 }^2 - { 1 \over 5 }^2 } = { 1 - { 2 \cdot { { 2 \over 5 }^2 } } - { 1 \over 5 }^2 } = { 1 - { 8 \over 25 } - { 1 \over 25 } } = { 1 - { 9 \over 25 } } = 0.64$.
2. Ask a question regarding the first element of the dataset (Green):
	Is the color green?
	1. We calculate the impurity of the `True` and `False` set separately:
		1. `True` set:
			`gini([Apple]) = 0`
		2. `False` set:
			`gini([Apple, Grape, Grape, Lemon])` => ${1 - { 1 \over 4 }^2 - {2 \over 4}^2 - {1 \over 4}^2 } = {1 - 2 \cdot {1 \over 4}^2 - {2 \over 4}^2 } = { 1 - { 2 \over 16 } - { 4 \over 16 } } = { 1 - { 3 \over 8 } } = 0.625$
   2. Then we obtain the average depending on how many elements there were in the set:
	   $average = { 1 \over 5 } \cdot$ `gini([Apple])` $+ { 4 \over 5 } \cdot$`gini([Apple, Grape, Grape, Lemon])`$= { 1 \over 5 } \cdot 0 + { 4 \over 5 } \cdot 0.625 = 0.5$
	3. The information gain is calculated by doing:
		$informationGain = impurity_0 - impurity_1 = 0.64 - 0.5 = 0.14$
3. We repeat the process 2. for the next question, keeping track of the question that returned the most information gain.
4. Once the question that has the highest information gain has been found, we set it as the root node of the tree.
5. We repeat the process recursively for the `True` and `False` branches of the root node.

| Color  | Diameter | Label | Is green? | 
| ------ | -------- | ----- | --------- |
| Green  | 3        | Apple | True      |
| Yellow | 3        | Apple | False     |
| Red    | 1        | Grape | False     |
| Red    | 1        | Grape | False     |
| Yellow | 3        | Lemon | False     |