2023-01-31 @ 14:03
Rodríguez López, Alejandro // UO281827

Tags:
	Hecho en #EPI
	Sobre #Sistemas_Inteligentes 
	Para #Apuntes 
	Otros: #Algoritmos
<hr>


# Zero R
Utiliza 0 atributos / condiciones. Calcula la clase más frecuente.
|Variable0 | Variable1 | ... | Jugar? |
|---|---|---|---|
|...|...|...|Sí|
|...|...|...|Sí|
|...|...|...|No|

La clase más frecuente es 'Sí', por lo tanto, el modelo predecirá 'Sí' para cualquier entrada.

# One R
Utiliza un atributo / condición.
De todos los atributos, utiliza aquel que parezca tener más efecto. Esto es, el que al predecir resulte en un menor número de errores.
Véase: Transparencia 26.

# Rote Learning

## Classification by neighborhood
La clase de un item `x` es aquella del item que más cerca tenga.
![[2.2 Algoritmos simples 31-01-2023 14.21.01.excalidraw|1900]]
El item '?' pertenecerá a la clase '+' porque el ítem más cercano que tiene es un '+' también. La diferencia se calcula utilizando la distancia euclídea y se normalizan los atributos. Si los atributos tuviesen diferentes pesos, deberían ser ponderados. Para valores nominales / discretos (como los colores) se utilizaría el 1 si son distintos y el 0 si son iguales.

# k-NN
En lugar de averiguar cuál es el vecino más próximo y reconocer su clase como la clase del item estudiado, se averiguan los k vecinos más cercanos y se predice que el item es de la clase más repetida en los distintos vecinos.

# Función de pérdida

$$y = h_\theta(x)$$
$$\theta \leftarrow argmin_\theta \cdot { { 1 } \over { |D| }} \cdot \sum_{(x,y) \in D} loss(y, h_\theta(x))$$
Donde $D$ es el conjunto de datos, $\theta$ el argumento a variar, y $loss(a, b)$ la función que calcula la pérdida entre los resultados $a$ y $b$.
No todos los atributos se deben de tener en cuenta. La función de pérdida se utiliza para descubrir cuánta importancia se le debe dar a cada atributo. Para ello, se busca minimizar la función con un atributo $\theta$.
